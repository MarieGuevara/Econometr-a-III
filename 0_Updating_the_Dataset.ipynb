{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary package\n",
        "import yfinance"
      ],
      "metadata": {
        "id": "dt5Ph4dcqMOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignoring warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "aLtl4s-mqQ4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the .download() method to get our data\n",
        "\n",
        "raw_data = yfinance.download (tickers = \"^GSPC ^FTSE ^N225 ^GDAXI\", start = \"1994-01-07\", end = \"2022-09-22\", interval = \"1d\", group_by = 'ticker', auto_adjust = True)\n",
        "\n",
        "# tickers -> The time series we are interested in - (in our case, these are the S&P, FTSE, NIKKEI and DAX)\n",
        "# start -> The starting date of our data set\n",
        "# end -> The ending date of our data set (at the time of upload, this is the current date)\n",
        "# interval -> The distance in time between two recorded observations. Since we're using daily closing prices, we set it equal to \"1d\", which indicates 1 day.\n",
        "# group_by -> The way we want to group the scraped data. Usually we want it to be \"ticker\", so that we have all the information about a time series in 1 variable.\n",
        "# auto_adjust -> Automatically adjust the closing prices for each period.\n",
        "# treads - > Whether to use threads for mass downloading."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0qLfaMzqT6K",
        "outputId": "12223587-0302-4361-8e81-1aa6529e6e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a back up copy in case we remove/alter elements of the data by mistake\n",
        "df_comp = raw_data.copy()"
      ],
      "metadata": {
        "id": "NPOx8k4yq-oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding new columns to the data set\n",
        "df_comp['spx'] = df_comp['^GSPC'].Close\n",
        "df_comp['dax'] = df_comp['^GDAXI'].Close\n",
        "df_comp['ftse'] = df_comp['^FTSE'].Close\n",
        "df_comp['nikkei'] = df_comp['^N225'].Close"
      ],
      "metadata": {
        "id": "nkyEoYvfrBtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_comp = df_comp.iloc[1:] # Removing the first elements, since we always start 1 period before the first, due to time zone differences of closing prices\n",
        "del df_comp['^N225']  # Removing the original tickers of the data set\n",
        "del df_comp['^GSPC']\n",
        "del df_comp['^GDAXI']\n",
        "del df_comp['^FTSE']\n",
        "df_comp=df_comp.asfreq('b') # Setting the frequency of the data\n",
        "df_comp=df_comp.fillna(method='ffill') # Filling any missing values"
      ],
      "metadata": {
        "id": "WuUpI4a7rE7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (df_comp.head()) # Displaying the first 5 elements to make sure the data was scraped correctly\n",
        "print (df_comp.tail()) # Making sure the last day we're including in the series are correct\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzvGgRvdrGVP",
        "outputId": "76b43d65-6c6a-475c-8f85-273738ec3eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   spx          dax         ftse        nikkei\n",
            "                                                              \n",
            "Date                                                          \n",
            "1994-01-07  469.899994  2224.949951  3446.000000  18124.009766\n",
            "1994-01-10  475.269989  2225.000000  3440.600098  18443.439453\n",
            "1994-01-11  474.130005  2228.100098  3413.800049  18485.250000\n",
            "1994-01-12  474.170013  2182.060059  3372.000000  18793.880859\n",
            "1994-01-13  472.470001  2142.370117  3360.000000  18577.259766\n",
            "                    spx           dax         ftse        nikkei\n",
            "                                                                \n",
            "Date                                                            \n",
            "2022-09-15  3901.350098  12956.660156  7282.100098  27875.910156\n",
            "2022-09-16  3873.330078  12741.259766  7236.700195  27567.650391\n",
            "2022-09-19  3899.889893  12803.240234  7236.700195  27567.650391\n",
            "2022-09-20  3855.929932  12670.830078  7192.700195  27688.419922\n",
            "2022-09-21  3789.929932  12767.150391  7237.600098  27313.130859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportar df a Excel\n",
        "df_comp.to_excel(\"Index_modified.xlsx\")"
      ],
      "metadata": {
        "id": "_BJHFtqcrljI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}